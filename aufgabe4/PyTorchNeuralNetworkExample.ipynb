{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b6d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F # import convolution functions like Relu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2313b7a1",
   "metadata": {},
   "source": [
    "## CPU oder GPU?\n",
    "Torch erlaubt das Ausführen (vor allem der aufwändigen Lernphase) des künstlichen neuronalen Netzes auf CPU oder GPU. Ob die GPU zur Verfügung steht hängt von dem installierten Python-Paket und der Unterstützung der Grafikkarte durch Torch ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "341f6269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccd21fc",
   "metadata": {},
   "source": [
    "## Knünstliches Neuronale Netzwerke in Torch\n",
    "In Torch werden neuronale Netzwerke wie durch Python-Klassen repräsentiert, die von der Klasse nn.Module erben.\n",
    "Diese beinhalten die Netztopologie sowie die Berechnungsart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292e5cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68636e7d",
   "metadata": {},
   "source": [
    "## Training des Netzes\n",
    "Das Training eines Netzes definiert man am besten als eigene Funktion. Das Training folgt hierbei dem bereits aus der Vorlesung bekannten Backpropagation-Verfahren. Die Art der Optimierung, der ```optimizer```, kann durch verschiedene bereits implementierte Optimierer bestimmt werden. Siehe hierzu auch den Aufruf in der ```main()``` Methode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "960fa94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f964e325",
   "metadata": {},
   "source": [
    "## Testing\n",
    "Auch das Testing ist am besten als Funktion zu kapseln. Hierbei wird das aktuelle ```model```, also das aktuelle künstliche neuronale Netz mit den Testdaten geprüft. Diese dürfen nicht Teil des Trainings sein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c9f02f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad38b950",
   "metadata": {},
   "source": [
    "## Die Hauptroutine\n",
    "Hier passiert alles:\n",
    "1. Die MNIST-Daten werden geladen und in Trainings- und Testdaten aufgeteilt\n",
    "2. Die Lernparameter und Optimierungsstrategien werden festgelegt\n",
    "3. Das Lernen erfolgt, gefolgt von einer Testphase pro Epoche.\n",
    "4. Das Netz wird abgespeichert (so kann es schnell wieder geladen werden, ohne dass ein erneutes Training erfolgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf14ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Download training data from open datasets.\n",
    "    training_data = datasets.MNIST(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Download test data from open datasets.\n",
    "    test_data = datasets.MNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    batch_size = 64\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    for X, y in test_dataloader:\n",
    "        print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "        print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "        break\n",
    "\n",
    "    model = NeuralNetwork().to(device)\n",
    "    print(model)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    \n",
    "    epochs = 10\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test(test_dataloader, model, loss_fn)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"model.pth\")\n",
    "    print(\"Saved PyTorch Model State to model.pth\")\n",
    "\n",
    "    model = NeuralNetwork().to(device)\n",
    "    model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "    classes = test_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6fdff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c808d49a3a24471ab21b114fa277099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441b8bfda2484b189e10eb178d6c7b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2291a71f2f674e7c8be30b4ecdcb4e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7d585ef3fe460987b3260ead2c0125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.312955  [   64/60000]\n",
      "loss: 0.745162  [ 6464/60000]\n",
      "loss: 0.385018  [12864/60000]\n",
      "loss: 0.355368  [19264/60000]\n",
      "loss: 0.219450  [25664/60000]\n",
      "loss: 0.316986  [32064/60000]\n",
      "loss: 0.227706  [38464/60000]\n",
      "loss: 0.389943  [44864/60000]\n",
      "loss: 0.348441  [51264/60000]\n",
      "loss: 0.270187  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.218695 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.158646  [   64/60000]\n",
      "loss: 0.195221  [ 6464/60000]\n",
      "loss: 0.102797  [12864/60000]\n",
      "loss: 0.229018  [19264/60000]\n",
      "loss: 0.128527  [25664/60000]\n",
      "loss: 0.222881  [32064/60000]\n",
      "loss: 0.076951  [38464/60000]\n",
      "loss: 0.259879  [44864/60000]\n",
      "loss: 0.214683  [51264/60000]\n",
      "loss: 0.212570  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.133261 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.083532  [   64/60000]\n",
      "loss: 0.133428  [ 6464/60000]\n",
      "loss: 0.077839  [12864/60000]\n",
      "loss: 0.167607  [19264/60000]\n",
      "loss: 0.084816  [25664/60000]\n",
      "loss: 0.139143  [32064/60000]\n",
      "loss: 0.050274  [38464/60000]\n",
      "loss: 0.199946  [44864/60000]\n",
      "loss: 0.162815  [51264/60000]\n",
      "loss: 0.174047  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.100090 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.050169  [   64/60000]\n",
      "loss: 0.105021  [ 6464/60000]\n",
      "loss: 0.069198  [12864/60000]\n",
      "loss: 0.127286  [19264/60000]\n",
      "loss: 0.062472  [25664/60000]\n",
      "loss: 0.088438  [32064/60000]\n",
      "loss: 0.039519  [38464/60000]\n",
      "loss: 0.152776  [44864/60000]\n",
      "loss: 0.112498  [51264/60000]\n",
      "loss: 0.144563  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.085817 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.032637  [   64/60000]\n",
      "loss: 0.080161  [ 6464/60000]\n",
      "loss: 0.054350  [12864/60000]\n",
      "loss: 0.096817  [19264/60000]\n",
      "loss: 0.058971  [25664/60000]\n",
      "loss: 0.062361  [32064/60000]\n",
      "loss: 0.030512  [38464/60000]\n",
      "loss: 0.115665  [44864/60000]\n",
      "loss: 0.090187  [51264/60000]\n",
      "loss: 0.120633  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.079900 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.024533  [   64/60000]\n",
      "loss: 0.055242  [ 6464/60000]\n",
      "loss: 0.043509  [12864/60000]\n",
      "loss: 0.068031  [19264/60000]\n",
      "loss: 0.050826  [25664/60000]\n",
      "loss: 0.047234  [32064/60000]\n",
      "loss: 0.023981  [38464/60000]\n",
      "loss: 0.089072  [44864/60000]\n",
      "loss: 0.078259  [51264/60000]\n",
      "loss: 0.098266  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.077551 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.019508  [   64/60000]\n",
      "loss: 0.039093  [ 6464/60000]\n",
      "loss: 0.038839  [12864/60000]\n",
      "loss: 0.039767  [19264/60000]\n",
      "loss: 0.041480  [25664/60000]\n",
      "loss: 0.039381  [32064/60000]\n",
      "loss: 0.021879  [38464/60000]\n",
      "loss: 0.065165  [44864/60000]\n",
      "loss: 0.066035  [51264/60000]\n",
      "loss: 0.070080  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.075168 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.018643  [   64/60000]\n",
      "loss: 0.027533  [ 6464/60000]\n",
      "loss: 0.036563  [12864/60000]\n",
      "loss: 0.023145  [19264/60000]\n",
      "loss: 0.030895  [25664/60000]\n",
      "loss: 0.032737  [32064/60000]\n",
      "loss: 0.017689  [38464/60000]\n",
      "loss: 0.050604  [44864/60000]\n",
      "loss: 0.057640  [51264/60000]\n",
      "loss: 0.047223  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.073154 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.016587  [   64/60000]\n",
      "loss: 0.019750  [ 6464/60000]\n",
      "loss: 0.030649  [12864/60000]\n",
      "loss: 0.016492  [19264/60000]\n",
      "loss: 0.018738  [25664/60000]\n",
      "loss: 0.025620  [32064/60000]\n",
      "loss: 0.011779  [38464/60000]\n",
      "loss: 0.035529  [44864/60000]\n",
      "loss: 0.046843  [51264/60000]\n",
      "loss: 0.031485  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.073191 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.013344  [   64/60000]\n",
      "loss: 0.012580  [ 6464/60000]\n",
      "loss: 0.023573  [12864/60000]\n",
      "loss: 0.014528  [19264/60000]\n",
      "loss: 0.012038  [25664/60000]\n",
      "loss: 0.017031  [32064/60000]\n",
      "loss: 0.008709  [38464/60000]\n",
      "loss: 0.024890  [44864/60000]\n",
      "loss: 0.037716  [51264/60000]\n",
      "loss: 0.021560  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.070237 \n",
      "\n",
      "Done!\n",
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b9eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
